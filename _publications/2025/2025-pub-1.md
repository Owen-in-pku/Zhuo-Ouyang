---
title:          "Projection Head is Secretly an Information Bottleneck"
date:           2025-01-26 00:00:00 +0800
selected:       true
pub:            "International Conference on Learning Representations (ICLR)"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2025"
# semantic_scholar_id: 204e3073870fae3d05bcbc2f6a8e263d9b72e776  # use this to retrieve citation count
abstract: >-
  <p> 
  We develop a new theoretical understanding for the role of the projection head in contrastive learning
  from the <strong>information-theoretic perspective</strong>. Mathematically, we rigorously derive both <strong>lower and upper
  bounds for the downstream performance</strong> of the features preceding the projection head.
  <p>
  Our findings indicate theoretical principles for designing an effective projection head: it should act as an
  <strong>information bottleneck</strong>, filtering out the irrelevant information and preserving the essential information
  for the contrastive objective.
  <p>
  Based on theoretical principles, we propose two categories of methods to improve projection head design,
  namely <strong>training regularization</strong> and <strong>structural regularization</strong>, that outperform previous approaches
  across a range of datasets and contrastive methods.
  </p>
# cover:          /assets/images/covers/cover3.jpg
authors:
  - Zhuo Ouyang
  - Kaiwen Hu
  - Qi Zhang
  - Yifei Wang
  - Yisen Wang
links:
  Paper: https://arxiv.org/abs/2503.00507v1
  Code: https://github.com/PKU-ML/Projector_Theory
  # Unsplash: https://unsplash.com/photos/orange-fruit-on-white-table-cloth-ISX_imp8t1o
  # emo: https://luost26.github.io/bubble-visual-hash
---
